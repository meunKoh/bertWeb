{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kkk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '[^\\w\\s.?!]'         # 특수기호제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '\\s+'         # tab to whitespace\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '\\d\\.\\d+'         \n",
    "    text = re.sub(pattern=pattern, repl='USRNUM', string=text)\n",
    "    pattern = '\\d+\\.'         \n",
    "    text = re.sub(pattern=pattern, repl='USRSEQ', string=text)\n",
    "    pattern = '\\d+'         \n",
    "    text = re.sub(pattern=pattern, repl='USRNUM', string=text)\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    pattern = '\\s+'         # tab to whitespace\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '[\\s]+'         \n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '[^ \\s.?!가-힣]+'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Language model data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "\n",
    "i=0\n",
    "for root, dirs, files in os.walk('C:\\\\Users\\\\kkk\\\\data\\\\petitions\\\\all'):\n",
    "#for root, dirs, files in os.walk('../data/petitions/all'):\n",
    "    for fname in files:\n",
    "        i = i + 1\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        file_names.append(full_fname)\n",
    "        if i == 2 :\n",
    "            break;\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kkk\\\\data\\\\petitions\\\\all\\\\petitions_2017-08',\n",
       " 'C:\\\\Users\\\\kkk\\\\data\\\\petitions\\\\all\\\\petitions_2017-09']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 items has been converted\n",
      "4000 items has been converted\n",
      "5000 items has been converted\n",
      "6000 items has been converted\n",
      "8000 items has been converted\n",
      "9000 items has been converted\n",
      "10000 items has been converted\n",
      "11000 items has been converted\n",
      "13000 items has been converted\n",
      "14000 items has been converted\n",
      "15000 items has been converted\n",
      "16000 items has been converted\n",
      "17000 items has been converted\n",
      "18000 items has been converted\n",
      "19000 items has been converted\n",
      "20000 items has been converted\n",
      "22000 items has been converted\n",
      "23000 items has been converted\n",
      "24000 items has been converted\n",
      "25000 items has been converted\n",
      "26000 items has been converted\n",
      "27000 items has been converted\n",
      "29000 items has been converted\n",
      "0 개 오류\n",
      "Total 29010 items has been converted\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = 'C:\\\\Users\\\\kkk\\\\PycharmProjects\\\\hug-face\\\\hug\\\\test\\\\train_30k_2.tsv'\n",
    "out_file_path = \"../test/petition.lm.30k-3.clean.train\"\n",
    "df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
    "#out_file_path = \"../data/petitions/petition.lm.all.clean.train\"\n",
    "with open(out_file_path, 'a', encoding='UTF8') as out_file:\n",
    "    df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        text = df['contents'][i]\n",
    "        content = clean_str(text)\n",
    "        sentences = sent_tokenize(content)\n",
    "\n",
    "        # BERT 모델은 문단 내 문장의 개수가 2개 이상이여야 함\n",
    "        if len(sentences) < 2:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            #print(sentence)\n",
    "            out_file.write(sentence + \"\\n\")\n",
    "\n",
    "        if i != 0 and i % 1000 == 0:\n",
    "            print(i, \"items has been converted\")\n",
    "\n",
    "        out_file.write(\"\\n\")\n",
    "\n",
    "        #if i == 5000:\n",
    "        #    break\n",
    "\n",
    "        \n",
    "print(str(k),'개 오류')\n",
    "print(\"Total {0} items has been converted\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 662 items has been converted\n",
      "2000 items has been converted\n",
      "3000 items has been converted\n",
      "4000 items has been converted\n",
      "5000 items has been converted\n",
      "6000 items has been converted\n",
      "9000 items has been converted\n",
      "12000 items has been converted\n",
      "13000 items has been converted\n",
      "14000 items has been converted\n",
      "15000 items has been converted\n",
      "16000 items has been converted\n",
      "Total 17010 items has been converted\n"
     ]
    }
   ],
   "source": [
    "out_file_path = \"../test/petition.lm.2.clean.train\"\n",
    "#out_file_path = \"../data/petitions/petition.lm.all.clean.train\"\n",
    "with open(out_file_path, 'a', encoding='UTF8') as out_file:\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, \"r\", encoding='utf-8', errors='ignore') as in_file:\n",
    "            datas = in_file.readlines()\n",
    "            \n",
    "            for i in range(len(datas)):\n",
    "                data = json.loads(datas[i])\n",
    "\n",
    "                content = clean_str(data['content'])\n",
    "\n",
    "                sentences = sent_tokenize(content)\n",
    "\n",
    "                # BERT 모델은 문단 내 문장의 개수가 2개 이상이여야 함\n",
    "                if len(sentences) < 2:\n",
    "                    continue\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    sentence = sentence.strip()\n",
    "\n",
    "                    out_file.write(sentence + \"\\n\")\n",
    "\n",
    "                if i != 0 and i % 1000 == 0:\n",
    "                    print(i, \"items has been converted\")\n",
    "\n",
    "                out_file.write(\"\\n\")\n",
    "\n",
    "                #if i == 5000:\n",
    "                #    break\n",
    "\n",
    "            print(\"Total {0} items has been converted\".format(len(datas)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
