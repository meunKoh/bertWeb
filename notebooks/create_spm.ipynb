{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '[^\\w\\s.?!]'         # 특수기호제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '\\s+'         # tab to whitespace\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '\\d\\.\\d+'         \n",
    "    text = re.sub(pattern=pattern, repl='USRNUM', string=text)\n",
    "    pattern = '\\d+\\.'         \n",
    "    text = re.sub(pattern=pattern, repl='USRSEQ', string=text)\n",
    "    pattern = '\\d+'         \n",
    "    text = re.sub(pattern=pattern, repl='USRNUM', string=text)\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    pattern = '\\s+'         # tab to whitespace\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '[^ 가-힣]+'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'구급대원 분들은 초가 시급한 분들입니다 여러분들  안녕하세요 우리나라  영화 '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_str('구급대원 분들은 0.000001초가 시급한 분들입니다. 1.여러분들 2. 안녕하세요 333.우리나라 333 22영화 123,000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for root, dirs, files in os.walk('./data/petitions/all'):\n",
    "    for fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        file_names.append(full_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/petitions/all\\\\petitions_2017-08',\n",
       " './data/petitions/all\\\\petitions_2017-09',\n",
       " './data/petitions/all\\\\petitions_2017-10',\n",
       " './data/petitions/all\\\\petitions_2017-11',\n",
       " './data/petitions/all\\\\petitions_2017-12']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 662 items has been converted\n",
      "Total 17010 items has been converted\n",
      "Total 5932 items has been converted\n",
      "Total 29426 items has been converted\n",
      "Total 18383 items has been converted\n"
     ]
    }
   ],
   "source": [
    "out_file_path = \"./data/petitions/petition.sp.all.train\"\n",
    "with open(out_file_path, 'a', encoding='UTF8') as out_file:\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, \"r\", encoding='utf-8', errors='ignore') as in_file:\n",
    "            datas = in_file.readlines()\n",
    "            \n",
    "            for i in range(len(datas)):\n",
    "                data = json.loads(datas[i])\n",
    "                content = clean_str(data['content'])\n",
    "                content.strip()\n",
    "                out_file.write(content + \"\\n\")\n",
    "\n",
    "            print(\"Total {0} items has been converted\".format(len(datas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 9663 items has been converted\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = 'C:\\\\Users\\\\kkk\\\\PycharmProjects\\\\hug-face\\\\hug\\\\test\\\\train_10000.tsv'\n",
    "df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
    "out_file_path = \"./petition.sp.10k.train\"\n",
    "\n",
    "with open(out_file_path, 'a', encoding='UTF8') as out_file:\n",
    "    df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        text = df['contents'][i]\n",
    "\n",
    "        content = clean_str(text)\n",
    "        content.strip()\n",
    "        out_file.write(content + \"\\n\")\n",
    "    print(\"Total {0} items has been converted\".format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/petitions/petition.sp.all.train'\n",
    "#templates = '--input={} --model_prefix={} --vocab_size={} --character_coverage={} --model_type={} --user_defined_symbols={} --unk_piece={} --bos_piece={} --eos_piece={} --pad_piece={}'\n",
    "templates = '--input={} --model_prefix={} --vocab_size={} --character_coverage={} --model_type={} --user_defined_symbols={} --pad_id={} --unk_piece={} --pad_piece={}'\n",
    "vocab_size = 30000\n",
    "prefix = '../data/petitions/sp-all-30000'\n",
    "character_coverage = 0.9998\n",
    "model_type = 'bpe'\n",
    "#user_defined_symbols='[SEQ],[NUM],[CLS],[MASK],[SEP]'\n",
    "user_defined_symbols='[CLS],[MASK],[SEP]'\n",
    "pad_id = 3\n",
    "unk_piece = '[UNK]'\n",
    "#bos_piece = '[S]'\n",
    "#eos_piece = '[/S]'\n",
    "pad_piece = '[PAD]'\n",
    "#cmd = templates.format(input_file, prefix, vocab_size, character_coverage, model_type, user_defined_symbols, unk_piece, bos_piece, eos_piece, pad_piece, pad_id)\n",
    "cmd = templates.format(input_file, prefix, vocab_size, character_coverage, model_type, user_defined_symbols, pad_id, unk_piece, pad_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spp = spm.SentencePieceProcessor()\n",
    "spp.Load('../data/petitions/sp-all-30000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = \"은행간 인수합병 반대와 장시간노동 해소를 요구중인 금융노조가 조합원 쟁의행위 찬반투표를 벌여 압도적 찬성률로 파업을 가결했다. USRSEQ일반적인 나 너 그리고 우리나라 대한민국 내 나이 USRNUM살이다.\"\n",
    "#spp.EncodeAsPieces(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_path = \"../data/petitions/vocab.txt\"\n",
    "\n",
    "with open(out_file_path, 'a', encoding='UTF8') as f_out:\n",
    "    vocab = {spp.IdToPiece(i): i for i in range(spp.GetPieceSize())}\n",
    "    for word in vocab:\n",
    "        f_out.write(word.split('\\t')[0].strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
